{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split as TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "class frame():\n",
    "  def __init__(self, imgpath, label, category, transform):\n",
    "    self.imgpath = imgpath\n",
    "    self.label = label\n",
    "    self.cat = category\n",
    "\n",
    "    self.X = transform(Image.open(imgpath).convert('RGB'))#.to(device)\n",
    "\n",
    "    if self.cat == \"fake\": self.y = 1\n",
    "    else: self.y = 0\n",
    "\n",
    "  def describe(self):\n",
    "    return self.imgpath, self.label, self.cat\n",
    "\n",
    "  def values(self):\n",
    "    return self.X, self.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(10),\n",
    "    torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    torchvision.transforms.Resize((SIZE, SIZE), antialias = True)\n",
    "    ]) #, torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((SIZE, SIZE), antialias = True)\n",
    "    ])\n",
    "\n",
    "def load(root, label, category, ftype, train_transform, test_transform, test_size = 0.2, sample = None):\n",
    "  '''\n",
    "  loads data as frame objects and train test split using the sampling and transform rules provided.\n",
    "  '''\n",
    "  path = os.path.join(root, label, category, ftype)\n",
    "  train_frames = []\n",
    "  test_frames = []\n",
    "\n",
    "  dir = os.listdir(path)\n",
    "\n",
    "  if sample: sample_size = sample\n",
    "  else: sample_size = len(dir)\n",
    "\n",
    "  indices = random.sample(range(len(dir)), sample_size)\n",
    "\n",
    "  train_indices, test_indices = TTS(indices, test_size = test_size)\n",
    "\n",
    "  for i in tqdm(train_indices):\n",
    "    image_name = dir[i]\n",
    "    new_frame = frame(imgpath = os.path.join(path, image_name),\n",
    "                      label = label,\n",
    "                      category = category,\n",
    "                      transform = train_transform)\n",
    "    train_frames.append(new_frame)\n",
    "\n",
    "  for i in tqdm(test_indices):\n",
    "    image_name = dir[i]\n",
    "    new_frame = frame(imgpath = os.path.join(path, image_name),\n",
    "                      label = label,\n",
    "                      category = category,\n",
    "                      transform = test_transform)\n",
    "    test_frames.append(new_frame)\n",
    "  return train_frames, test_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:54<00:00, 14.55it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 70.80it/s]\n",
      "100%|██████████| 800/800 [00:56<00:00, 14.27it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 59.35it/s]\n",
      "100%|██████████| 800/800 [01:01<00:00, 12.98it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 53.23it/s]\n",
      "100%|██████████| 800/800 [01:09<00:00, 11.49it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 56.82it/s]\n",
      "100%|██████████| 800/800 [01:15<00:00, 10.63it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 57.30it/s]\n",
      "100%|██████████| 800/800 [01:06<00:00, 12.06it/s]\n",
      "100%|██████████| 200/200 [00:05<00:00, 39.67it/s]\n",
      "100%|██████████| 1600/1600 [02:19<00:00, 11.43it/s]\n",
      "100%|██████████| 400/400 [00:07<00:00, 53.06it/s]\n",
      "100%|██████████| 800/800 [01:14<00:00, 10.76it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.26it/s]\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = \"C:/Users/chuag/OneDrive - Nanyang Technological University/Desktop/BCG 4.2/FYP/code/data/FF++\"\n",
    "\n",
    "# DeepFakeDetection dataset\n",
    "DFD_train, DFD_test = load(ROOT_PATH,\"fake\",\"DeepFakeDetection\",\"faces\",train_transform,test_transform,0.2,1000)\n",
    "DF_train, DF_test = load(ROOT_PATH,\"fake\",\"Deepfakes\",\"faces\",train_transform,test_transform,0.2,1000)\n",
    "F2F_train, F2F_test = load(ROOT_PATH,\"fake\",\"Face2Face\",\"faces\",train_transform,test_transform,0.2,1000)\n",
    "SHIFTER_train, SHIFTER_test = load(ROOT_PATH,\"fake\",\"FaceShifter\",\"faces\",train_transform,test_transform,0.2,1000)\n",
    "SWAP_train, SWAP_test = load(ROOT_PATH,\"fake\",\"FaceSwap\",\"faces\",train_transform,test_transform,0.2,1000)\n",
    "NT_train, NT_test =  load(ROOT_PATH,\"fake\",\"NeuralTextures\",\"faces\",train_transform,test_transform,0.2,1000)\n",
    "YT_train, YT_test = load(ROOT_PATH,\"real\",\"youtube\",\"faces\",train_transform,test_transform,0.2,2000)\n",
    "ACTORS_train, ACTORS_test = load(ROOT_PATH,\"real\",\"actors\",\"faces\",train_transform,test_transform,0.2,1000)\n",
    "\n",
    "training = DFD_train + DF_train + F2F_train + SHIFTER_train + SWAP_train + NT_train + YT_train + ACTORS_train\n",
    "testing = DFD_test + DF_test + F2F_test + SHIFTER_test + SWAP_test + NT_test + YT_test + ACTORS_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training)\n",
    "random.shuffle(testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
